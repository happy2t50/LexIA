# ğŸš€ GuÃ­a de Setup Completo: PostgreSQL + OLAP + RAG

Esta guÃ­a te llevarÃ¡ paso a paso para configurar el sistema completo con PostgreSQL, OLAP Cube y RAG.

## ğŸ“‹ Requisitos Previos

- âœ… PostgreSQL 14+ instalado
- âœ… Node.js 18+
- âœ… npm o yarn

---

## PASO 1: Configurar PostgreSQL

### 1.1 Crear Base de Datos

```bash
# Conectarse a PostgreSQL
psql -U postgres

# Dentro de psql:
CREATE DATABASE lexia_db;

# Salir
\q
```

### 1.2 Ejecutar Migraciones

```bash
# Desde la raÃ­z del proyecto
cd LexIA2.0

# MigraciÃ³n 1: Tablas principales
psql -U postgres -d lexia_db -f database/migrations/001_create_tables.sql

# MigraciÃ³n 2: Soporte vectorial (pgvector)
psql -U postgres -d lexia_db -f database/migrations/002_add_vector_support.sql
```

**Nota:** Si `002_add_vector_support.sql` falla con error de pgvector:

```bash
# Instalar pgvector primero

# Ubuntu/Debian:
sudo apt-get install postgresql-14-pgvector

# macOS:
brew install pgvector

# Luego volver a ejecutar la migraciÃ³n
```

### 1.3 Verificar Tablas Creadas

```bash
psql -U postgres -d lexia_db

# Dentro de psql:
\dt

# DeberÃ­as ver:
# - usuarios
# - abogados
# - negocios
# - consultas (OLAP)
# - documentos_legales (RAG)
# - documento_chunks (RAG con vectores)
# - rag_consultas
# - Y mÃ¡s...

# Verificar extensiones
\dx

# DeberÃ­as ver:
# - uuid-ossp
# - vector (pgvector)

\q
```

---

## PASO 2: Configurar OLAP Cube Service

### 2.1 Instalar Dependencias

```bash
cd microservices/IA/olap-cube
npm install
```

### 2.2 Configurar Variables de Entorno

El archivo `.env` ya fue creado con:

```env
PORT=3001
USE_POSTGRESQL=true
DB_HOST=localhost
DB_PORT=5432
DB_NAME=lexia_db
DB_USER=postgres
DB_PASSWORD=password
DB_POOL_MAX=20
```

**âš ï¸ IMPORTANTE:** Cambia `DB_PASSWORD` por tu contraseÃ±a real de PostgreSQL.

### 2.3 Iniciar Servicio

```bash
npm run dev
```

DeberÃ­as ver:

```
ğŸ“Š OLAP Cube usando PostgreSQL
ğŸ” OLAP Cube Service corriendo en puerto 3001
```

### 2.4 Verificar Health Check

```bash
curl http://localhost:3001/health
```

Respuesta esperada:

```json
{
  "status": "OK",
  "service": "OLAP Cube Service",
  "database": "Connected"
}
```

---

## PASO 3: Configurar RAG Service

### 3.1 Instalar Dependencias

```bash
cd ../rag
npm install
```

**Nota:** La primera vez puede tomar varios minutos porque descarga el modelo de embeddings (~80MB).

### 3.2 Configurar Variables de Entorno

El archivo `.env` ya fue creado. Verifica:

```env
PORT=3009
DB_HOST=localhost
DB_PORT=5432
DB_NAME=lexia_db
DB_USER=postgres
DB_PASSWORD=password  # âš ï¸ Cambiar por tu contraseÃ±a

EMBEDDING_MODEL=Xenova/all-MiniLM-L6-v2
TOP_K_RESULTS=5
SIMILARITY_THRESHOLD=0.7
```

### 3.3 Iniciar Servicio

```bash
npm run dev
```

DeberÃ­as ver:

```
ğŸ”„ Inicializando RAG Service...
ğŸ”„ Cargando modelo de embeddings: Xenova/all-MiniLM-L6-v2...
âœ… Modelo de embeddings cargado exitosamente
âœ… RAG Service listo
ğŸš€ RAG Service corriendo en puerto 3009
```

**Nota:** La primera ejecuciÃ³n tomarÃ¡ ~30-60 segundos mientras descarga el modelo.

### 3.4 Verificar Health Check

```bash
curl http://localhost:3009/health
```

Respuesta esperada:

```json
{
  "status": "OK",
  "service": "RAG Service",
  "database": "Connected",
  "embeddingModel": "Xenova/all-MiniLM-L6-v2",
  "modelInitialized": true,
  "ragInitialized": true
}
```

---

## PASO 4: Indexar Documentos Legales

### 4.1 Indexar Documentos Iniciales

Los documentos fueron insertados por la migraciÃ³n, pero necesitan ser procesados para generar embeddings:

```bash
curl -X POST http://localhost:3009/index-all
```

DeberÃ­as ver en la consola del servicio:

```
ğŸ“„ Encontrados 7 documentos para indexar
  âœ… ArtÃ­culo 123 - ViolaciÃ³n de SemÃ¡foro en Rojo (3 chunks)
  âœ… ArtÃ­culo 106 - Exceso de Velocidad (3 chunks)
  âœ… ArtÃ­culo 138 - Estacionamiento Prohibido (2 chunks)
  âœ… ArtÃ­culo 152 - ConducciÃ³n bajo Efectos del Alcohol (3 chunks)
  âœ… ArtÃ­culo 131 - Conducir sin Licencia (3 chunks)
  âœ… ArtÃ­culo 109 - No Portar SOAT (3 chunks)
  âœ… ArtÃ­culo 110 - Obligaciones en caso de Accidente (2 chunks)
âœ… IndexaciÃ³n completa: 7 documentos
```

### 4.2 Verificar IndexaciÃ³n

```bash
curl http://localhost:3009/stats
```

Respuesta esperada:

```json
{
  "success": true,
  "baseConocimiento": {
    "total_documentos": "7",
    "total_chunks": "19",
    "total_categorias": "5",
    "total_clusters": "5"
  },
  "modeloEmbeddings": {
    "nombre": "Xenova/all-MiniLM-L6-v2",
    "dimension": 384,
    "inicializado": true
  }
}
```

---

## PASO 5: Probar el Sistema RAG

### 5.1 BÃºsqueda Simple

```bash
curl -X POST http://localhost:3009/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "me pasÃ© un semÃ¡foro en rojo"
  }'
```

Respuesta esperada:

```json
{
  "success": true,
  "consulta": "me pasÃ© un semÃ¡foro en rojo",
  "chunksRecuperados": [
    {
      "id": "...",
      "contenido": "Todo conductor que no respete la seÃ±al...",
      "similitud": 0.89,
      "tituloDocumento": "ArtÃ­culo 123 - ViolaciÃ³n de SemÃ¡foro",
      "categoria": "SeÃ±alizaciÃ³n",
      "cluster": "C1"
    }
  ],
  "contexto": "[Documento 1: ArtÃ­culo 123]\n...",
  "tiempoBusquedaMs": 120
}
```

### 5.2 BÃºsqueda con Filtro por Cluster

```bash
curl -X POST http://localhost:3009/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "multa por velocidad",
    "cluster": "C1"
  }'
```

---

## PASO 6: Iniciar Clustering ML (Opcional pero Recomendado)

Para usar la bÃºsqueda inteligente que auto-detecta el cluster:

### 6.1 Iniciar Clustering Service

```bash
cd ../clustering-ml
npm run dev
```

### 6.2 Probar BÃºsqueda Inteligente

```bash
curl -X POST http://localhost:3009/search-smart \
  -H "Content-Type: application/json" \
  -d '{
    "query": "me multaron por exceso de velocidad",
    "usuarioId": "user123"
  }'
```

Esto automÃ¡ticamente:
1. Predice que es cluster C1
2. Busca documentos relacionados con velocidad
3. Retorna resultados contextualizados

---

## PASO 7: Integrar con NLP y Otros Servicios

### 7.1 Iniciar NLP Service

```bash
cd ../nlp
npm run dev
```

### 7.2 Flujo Completo

```javascript
// 1. Usuario hace consulta
const consulta = "me pasÃ© un semÃ¡foro en rojo";

// 2. NLP procesa
const nlpResponse = await fetch('http://localhost:3004/process', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ textoConsulta: consulta })
});

// 3. RAG busca contexto
const ragResponse = await fetch('http://localhost:3009/search-smart', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ query: consulta })
});

// 4. Usar contexto para generar respuesta
const resultado = await ragResponse.json();
console.log(resultado.contexto); // Contexto legal relevante
```

---

## ğŸ§ª Tests de VerificaciÃ³n

### Test 1: PostgreSQL

```bash
psql -U postgres -d lexia_db -c "SELECT COUNT(*) FROM consultas;"
```

### Test 2: OLAP Cube

```bash
curl http://localhost:3001/consultas
```

### Test 3: RAG Embeddings

```bash
curl -X POST http://localhost:3009/embedding \
  -H "Content-Type: application/json" \
  -d '{"text": "hola mundo"}'
```

DeberÃ­a retornar vector de 384 dimensiones.

### Test 4: BÃºsqueda Vectorial

```bash
curl -X POST http://localhost:3009/search \
  -H "Content-Type: application/json" \
  -d '{"query": "alcoholÃ­metro"}'
```

DeberÃ­a encontrar documentos relacionados con cluster C3.

---

## ğŸ› Troubleshooting

### Error: "Cannot find module '@xenova/transformers'"

```bash
cd microservices/IA/rag
npm install @xenova/transformers
```

### Error: "extension 'vector' does not exist"

```bash
# Instalar pgvector
sudo apt-get install postgresql-14-pgvector  # Linux
brew install pgvector  # macOS

# Luego en PostgreSQL:
psql -U postgres -d lexia_db -c "CREATE EXTENSION vector;"
```

### Error: "ECONNREFUSED" al conectar a PostgreSQL

Verifica que PostgreSQL estÃ© corriendo:

```bash
# Linux
sudo systemctl status postgresql

# macOS
brew services list

# Iniciar si no estÃ¡ corriendo
sudo systemctl start postgresql  # Linux
brew services start postgresql@14  # macOS
```

### Modelo de embeddings tarda mucho en cargar

Primera carga: ~30-60 segundos (descarga modelo)
Siguientes: ~5-10 segundos (lee de cachÃ©)

UbicaciÃ³n del cachÃ©:
- Linux/macOS: `~/.cache/huggingface/`
- Windows: `C:\Users\{usuario}\.cache\huggingface\`

---

## ğŸ“Š Arquitectura Final

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Usuario   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Frontend / API Gateway          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚
       â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NLP Service â”‚      â”‚ Auth Service â”‚
â”‚  (port 3004)â”‚      â”‚  (port 3003) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Clustering ML    â”‚
â”‚   (port 3002)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RAG Service    â”‚â—„â”€â”€â”€â”€â”€â–ºâ”‚  OLAP Cube      â”‚
â”‚   (port 3009)    â”‚       â”‚  (port 3001)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                            â”‚
       â–¼                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         PostgreSQL + pgvector            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ consultasâ”‚  â”‚ documento_chunks   â”‚   â”‚
â”‚  â”‚  (OLAP)  â”‚  â”‚  (vectores 384D)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Checklist Final

- [ ] PostgreSQL instalado y corriendo
- [ ] Ambas migraciones ejecutadas (001 y 002)
- [ ] ExtensiÃ³n pgvector instalada
- [ ] OLAP Cube conectado a PostgreSQL
- [ ] RAG Service inicializado
- [ ] Modelo de embeddings cargado
- [ ] Documentos indexados (7 documentos, ~19 chunks)
- [ ] Tests de bÃºsqueda funcionando
- [ ] Clustering ML corriendo (opcional)
- [ ] IntegraciÃ³n completa probada

---

## ğŸ‰ Â¡Sistema Listo!

Ahora tienes:

âœ… **OLAP Cube** conectado a PostgreSQL para anÃ¡lisis multidimensional
âœ… **RAG Service** con embeddings locales (sin OpenAI)
âœ… **Base de datos vectorial** con pgvector para bÃºsqueda semÃ¡ntica
âœ… **Clustering automÃ¡tico** para clasificaciÃ³n inteligente
âœ… **Sistema completo** sin dependencias de APIs externas

**PrÃ³ximos pasos:**
1. Agregar mÃ¡s documentos legales
2. Integrar con frontend
3. Implementar generaciÃ³n de respuestas (LLM local o templates)
4. Escalar con mÃ¡s datos
